{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Experiment tracing with MLflow\n",
    "\n",
    "Question [here](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/02-experiment-tracking/homework.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Install MLflow\n",
    "\n",
    "Run the command mlflow --version and check the output.\n",
    "\n",
    "What's the version that you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.1\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1.\n",
    "Version 1.26.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Download and preprocess the data\n",
    "\n",
    "Use the script preprocess_data.py located in the folder homework to preprocess the data.\n",
    "\n",
    "The script will\n",
    "\n",
    "* load the data from the folder <TAXI_DATA_FOLDER> (the folder where you have downloaded the data),\n",
    "* fit a DictVectorizer on the training set (January 2021 data),\n",
    "* save the preprocessed datasets and the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py --raw_data_path ../data --dest_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dv.pkl  test.pkl  train.pkl  valid.pkl\n"
     ]
    }
   ],
   "source": [
    "%ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2. \n",
    "4 files were saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question3. Train a model with autolog\n",
    "Modify the given script to enable autologging with MLflow, execute the script and then launch the MLflow UI to check that the experiment run was properly tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/05/29 23:41:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/jaimeh94/anaconda3/envs/mlops-zoomcamp/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3.\n",
    "17 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Launch the tracking server locally\n",
    "\n",
    "Your task is to\n",
    "\n",
    "launch the tracking server on your local machine\n",
    "select a SQLite db for the backend store and a folder called artifacts for the artifacts store\n",
    "You should keep the tracking server running to work on the next two exercises that use the server.\n",
    "\n",
    "In addition to backend-store-uri, what else do you need to pass to properly configure the server?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow ui [OPTIONS]\n",
      "\n",
      "  Launch the MLflow tracking UI for local viewing of run results. To launch a\n",
      "  production server, use the \"mlflow server\" command instead.\n",
      "\n",
      "  The UI will be visible at http://localhost:5000 by default, and only accepts\n",
      "  connections from the local machine. To let the UI server accept connections\n",
      "  from other machines, you will need to pass ``--host 0.0.0.0`` to listen on\n",
      "  all network interfaces (or a specific interface address).\n",
      "\n",
      "Options:\n",
      "  --backend-store-uri PATH     URI to which to persist experiment and run\n",
      "                               data. Acceptable URIs are SQLAlchemy-compatible\n",
      "                               database connection strings (e.g.\n",
      "                               'sqlite:///path/to/file.db') or local\n",
      "                               filesystem URIs (e.g.\n",
      "                               'file:///absolute/path/to/directory'). By\n",
      "                               default, data will be logged to ./mlruns\n",
      "  --default-artifact-root URI  Directory in which to store artifacts for any\n",
      "                               new experiments created. For tracking server\n",
      "                               backends that rely on SQL, this option is\n",
      "                               required in order to store artifacts. Note that\n",
      "                               this flag does not impact already-created\n",
      "                               experiments with any previous configuration of\n",
      "                               an MLflow server instance. If the --serve-\n",
      "                               artifacts option is specified, the default\n",
      "                               artifact root is mlflow-artifacts:/. Otherwise,\n",
      "                               the default artifact root is ./mlruns.\n",
      "  --serve-artifacts            If specified, enables serving of artifact\n",
      "                               uploads, downloads, and list requests by\n",
      "                               routing these requests to the storage location\n",
      "                               that is specified by '--artifact-destination'\n",
      "                               directly through a proxy. The default location\n",
      "                               that these requests are served from is a local\n",
      "                               './mlartifacts' directory which can be\n",
      "                               overridden via the '--artifacts-destination'\n",
      "                               argument. Default: False\n",
      "  --artifacts-destination URI  The base artifact location from which to\n",
      "                               resolve artifact upload/download/list requests\n",
      "                               (e.g. 's3://my-bucket'). Defaults to a local\n",
      "                               './mlartifacts' directory. This option only\n",
      "                               applies when the tracking server is configured\n",
      "                               to stream artifacts and the experiment's\n",
      "                               artifact root location is http or mlflow-\n",
      "                               artifacts URI.\n",
      "  -p, --port INTEGER           The port to listen on (default: 5000).\n",
      "  -h, --host HOST              The network address to listen on (default:\n",
      "                               127.0.0.1). Use 0.0.0.0 to bind to all\n",
      "                               addresses if you want to access the tracking\n",
      "                               server from other machines.\n",
      "  --help                       Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4.\n",
    "--default-artifact-root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Tune the hyperparameters of the model\n",
    "Your task is to modify the script hpo.py and make sure that the validation RMSE is logged to MLflow for each run of the hyperparameter optimization (you will need to add a few lines of code to the objective function) and run the script without passing any parameters.\n",
    "\n",
    "What's the best validation RMSE that you got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 50/50 [04:19<00:00,  5.19s/trial, best loss: 6.6284257482044735]\n"
     ]
    }
   ],
   "source": [
    "!python hpo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 5.\n",
    "6.628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Promote the best model to the model registry\n",
    "\n",
    "Your task is to update the script register_model.py so that it selects the model with the lowest RMSE on the test set and registers it to the model registry.\n",
    "\n",
    "What is the test RMSE of the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python register_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 6.\n",
    "6.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f5552ad325920dda88e9d29dcc912bfe1d37310efae863aa8f61a41391a8b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlops-zoomcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
